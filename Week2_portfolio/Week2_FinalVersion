# Import necessary libraries
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Load your dataset using an absolute path
file_path = 'C:/Sudhish_Folders/SwinburneUNI/Studio_Portfolios/venv/Include/Portfolio_Submissions/water_potability.csv'

try:
    data = pd.read_csv(file_path)
    print("File loaded successfully!")
except FileNotFoundError:
    print(f"Error: The file was not found at the specified path: {file_path}")
    exit()

# Display the first few rows of the dataset
print("\nDataset Overview:")
print(data.head())

# Check how many rows and columns are there
print("\nShape of the dataset:")
print(data.shape)

# Display column names and their types
print("\nColumn Names and Data Types:")
print(data.dtypes)

# Data Cleaning
# Remove duplicate entries
data = data.drop_duplicates()
print("\nShape after removing duplicates:")
print(data.shape)

# Check for missing values
print("\nMissing Values:")
print(data.isnull().sum())

# Fill missing values (example: fill with mean or use other imputation methods)
data.fillna(data.mean(), inplace=True)

# Check for outliers using boxplots
for column in data.select_dtypes(include=['float64', 'int64']).columns:
    plt.figure(figsize=(10, 6))
    sns.boxplot(data[column])
    plt.title(f"Box Plot: {column}")
    plt.show()

# Summary statistics of all variables
print("\nSummary Statistics:")
print(data.describe())

# Identify target variable and predictors
target_variable = 'Potability'
predictors = data.drop(columns=[target_variable])

# Feature Selection using RandomForestClassifier
X = predictors
y = data[target_variable]
model = RandomForestClassifier()
model.fit(X, y)
feature_importances = pd.DataFrame({
    'Feature': X.columns,
    'Score': model.feature_importances_
}).sort_values(by='Score', ascending=False)

print("\nFeature Selection Scores:")
print(feature_importances)

# Split the data for training and testing
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Train a Decision Tree model
dt_model = DecisionTreeClassifier()
dt_model.fit(X_train, y_train)

# Predict on the test set
y_pred = dt_model.predict(X_test)

# Evaluate model performance
report = classification_report(y_test, y_pred, output_dict=True)
report_df = pd.DataFrame(report).transpose()

print("\nDecision Tree Model Performance:")
print(report_df)

# Univariate analysis for predictors
for column in predictors.columns:
    plt.figure(figsize=(10, 6))
    sns.histplot(data[column], bins=20, kde=True)
    plt.title(f"Univariate Analysis: {column}")
    plt.show()

# Conduct a multivariate analysis
sns.pairplot(data[predictors.columns])
plt.suptitle("Multivariate Analysis: Pair Plot", y=1.02)
plt.show()

# Identify pairwise correlations among the variables and plot them in a heatmap
correlation_matrix = data.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix Heatmap")
plt.show()
